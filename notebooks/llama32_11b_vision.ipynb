{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "from transformers import MllamaForConditionalGeneration, AutoProcessor\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "login(token=os.getenv(\"HF_TOKEN\"))"
   ],
   "id": "80573795eafb6ad2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "HF_MODEL_ID = \"meta-llama/Llama-3.2-11B-Vision\"\n",
    "EVALUATION_IMAGES_DIR = \"/home/ubuntu/meta_hackathon_oslo/evaluation/handwritten\"\n",
    "MAX_NEW_TOKENS = 100"
   ],
   "id": "d9877e2a9d80ea3f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = MllamaForConditionalGeneration.from_pretrained(\n",
    "    HF_MODEL_ID,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(HF_MODEL_ID)"
   ],
   "id": "fc9b51ee0e03642",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def inference(image_url):\n",
    "    image = Image.open(image_url)\n",
    "    prompt = \"<|image|><|begin_of_text|>Please summarise the contents of this image.\"\n",
    "\n",
    "    inputs = processor(image, prompt, return_tensors=\"pt\").to(model.device)\n",
    "    output = model.generate(**inputs, max_new_tokens=MAX_NEW_TOKENS)\n",
    "\n",
    "    return processor\\\n",
    "        .decode(output[0])\\\n",
    "        .replace(prompt, \"\")\\\n",
    "        .replace(\"<|begin_of_text|>\", \"\")"
   ],
   "id": "a2f375ea7713b83a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "directory = Path(EVALUATION_IMAGES_DIR)\n",
    "\n",
    "for image_path in directory.iterdir():\n",
    "    inference_result = inference(image_path)\n",
    "    print(inference_result)"
   ],
   "id": "c7820e22ab34f29e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
