{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import xml.etree.ElementTree as ET\n",
    "from datasets import Dataset, DatasetDict, Features, Image, Value\n",
    "\n",
    "load_dotenv()"
   ],
   "id": "5086bc8017960d03",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define dataset path\n",
    "DATASET_DIR = \"/home/ubuntu/meta_hackathon_oslo/datasets/norhand_v3\"\n",
    "HF_ORG_NAME = \"MykMaks\"\n",
    "HF_REPO_NAME = \"norhand_v3\""
   ],
   "id": "24da25f19a566892",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def parse_xml_label(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    label = \"\"\n",
    "\n",
    "    namespace = {'ns': 'http://schema.primaresearch.org/PAGE/gts/pagecontent/2013-07-15'}\n",
    "    unicode_elem = root.find(\".//ns:Page/ns:TextRegion/ns:TextEquiv/ns:Unicode\", namespace)\n",
    "\n",
    "    if unicode_elem is not None:\n",
    "        label = unicode_elem.text\n",
    "\n",
    "    return label"
   ],
   "id": "f6172cd4e5ac3610",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_dataframe(image_dir, label_dir):\n",
    "    data = []\n",
    "    for image_file in os.listdir(image_dir):\n",
    "        if image_file.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            image_path = os.path.join(image_dir, image_file)\n",
    "            xml_file = os.path.join(label_dir, os.path.splitext(image_file)[0] + '.xml')\n",
    "            if os.path.exists(xml_file):\n",
    "                data.append({\n",
    "                    'image': image_path,\n",
    "                    'solution': parse_xml_label(xml_file),\n",
    "                    'original_question': \"\",\n",
    "                    'original_answer': \"\",\n",
    "                    'question': \"What's on this image?\",\n",
    "                    'language': \"no\",\n",
    "                    'source': f\"Zenodo/{HF_REPO_NAME}\",\n",
    "                })\n",
    "    return pd.DataFrame(data)\n"
   ],
   "id": "c1d58c76ed59753",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_dataset_dict(base_dir):\n",
    "    dataset_dict = {}\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        image_dir = os.path.join(base_dir, split, 'images')\n",
    "        label_dir = os.path.join(base_dir, split, 'page')\n",
    "        df = create_dataframe(image_dir, label_dir)\n",
    "        features = Features({\n",
    "            'image': Image(),\n",
    "            'solution': Value('string'),\n",
    "            'original_question': Value('string'),\n",
    "            'original_answer': Value('string'),\n",
    "            'question': Value('string'),\n",
    "            'language': Value('string'),\n",
    "            'source': Value('string'),\n",
    "        })\n",
    "        dataset = Dataset.from_pandas(df, features=features)\n",
    "        dataset_dict[split] = dataset\n",
    "    return DatasetDict(dataset_dict)"
   ],
   "id": "e75390ccb46f8b4b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def push_to_hub(data_dict, repo_name, repo_owner):\n",
    "    # api = HfApi()\n",
    "    # api.create_repo(\n",
    "    #     token=os.getenv(\"HF_TOKEN\"),\n",
    "    #     name=repo_name,\n",
    "    #     organization=repo_owner,\n",
    "    #     repo_type='dataset',\n",
    "    #     exist_ok=True\n",
    "    # )\n",
    "    data_dict.push_to_hub(f\"{repo_owner}/{repo_name}\")"
   ],
   "id": "6513c9ca93b9164f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create the DatasetDict\n",
    "dataset_dict = create_dataset_dict(DATASET_DIR)"
   ],
   "id": "e09c7ac84f7c98b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "dataset_dict[\"test\"][0]",
   "id": "6204fc1e036c127a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Push the dataset to the Hugging Face Hub\n",
    "push_to_hub(dataset_dict, repo_name=HF_REPO_NAME, repo_owner=HF_ORG_NAME)"
   ],
   "id": "eb49d2fe39664c0b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
